{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9wG3fxPxnFO",
        "outputId": "cfdfb9ed-65a1-4bbf-dfa9-6fce148fc11d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.46.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.11-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.45.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.6.15)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Downloading streamlit-1.46.1-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.11-py3-none-any.whl (25 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.2.11 streamlit-1.46.1 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pandas numpy matplotlib seaborn plotly pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # This opens a file picker to upload customers-100.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "VzccH89lyLI7",
        "outputId": "abb390bd-a53a-4701-d64b-8d717f560ec5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-36bcc6b6-5709-412d-8eec-c8c48b2ab046\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-36bcc6b6-5709-412d-8eec-c8c48b2ab046\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving customers-100.csv to customers-100.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "from pathlib import Path\n",
        "\n",
        "# Set page config\n",
        "st.set_page_config(page_title=\"Customer Manager & Analyzer\", layout=\"wide\")\n",
        "\n",
        "# Load and clean data\n",
        "@st.cache_data\n",
        "def load_and_clean_data(/content/customers-100.csv):\n",
        "    df = pd.read_csv(file_path)\n",
        "    # Remove duplicates\n",
        "    df = df.drop_duplicates()\n",
        "    # Drop rows with missing critical values\n",
        "    df = df.dropna(subset=['First Name', 'Email'])\n",
        "    # Drop unnecessary columns\n",
        "    df = df.drop(columns=['Index', 'Subscription Date'], errors='ignore')\n",
        "    return df\n",
        "\n",
        "# File path\n",
        "file_path = \"customers-100.csv\"\n",
        "try:\n",
        "    df = load_and_clean_data(file_path)\n",
        "except FileNotFoundError:\n",
        "    st.error(\"customers-100.csv not found! Please upload the file.\")\n",
        "    st.stop()\n",
        "\n",
        "# Sidebar for navigation\n",
        "st.sidebar.title(\"Navigation\")\n",
        "view = st.sidebar.radio(\"Select View\", [\"Overview\", \"Table\", \"Stats\"])\n",
        "\n",
        "# Overview View\n",
        "if view == \"Overview\":\n",
        "    st.title(\"Customer Data Overview\")\n",
        "    st.write(\"Summary statistics of the cleaned customer dataset.\")\n",
        "\n",
        "    # Summary stats\n",
        "    total_customers = len(df)\n",
        "    unique_countries = df['Country'].nunique()\n",
        "    most_common_country = df['Country'].mode()[0]\n",
        "    top_3_cities = df['City'].value_counts().head(3).index.tolist()\n",
        "    top_5_companies = df['Company'].value_counts().head(5).index.tolist()\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        st.metric(\"Total Customers\", total_customers)\n",
        "        st.metric(\"Unique Countries\", unique_countries)\n",
        "    with col2:\n",
        "        st.metric(\"Most Common Country\", most_common_country)\n",
        "        st.write(\"Top 3 Cities:\", \", \".join(top_3_cities))\n",
        "        st.write(\"Top 5 Companies:\", \", \".join(top_5_companies))\n",
        "\n",
        "# Table View\n",
        "elif view == \"Table\":\n",
        "    st.title(\"Editable Customer Table\")\n",
        "    st.write(\"Edit the dataset below and download the updated version.\")\n",
        "\n",
        "    # Editable table\n",
        "    edited_df = st.data_editor(df, num_rows=\"dynamic\")\n",
        "\n",
        "    # Export button\n",
        "    if st.button(\"Export Edited Data\"):\n",
        "        edited_df.to_csv(\"edited_customers.csv\", index=False)\n",
        "        st.download_button(\n",
        "            label=\"Download Edited CSV\",\n",
        "            data=Path(\"edited_customers.csv\").read_bytes(),\n",
        "            file_name=\"edited_customers.csv\",\n",
        "            mime=\"text/csv\"\n",
        "        )\n",
        "\n",
        "# Stats View\n",
        "elif view == \"Stats\":\n",
        "    st.title(\"Customer Data Visualizations\")\n",
        "    st.write(\"Graphical insights into customer distribution.\")\n",
        "\n",
        "    # Bar chart: Top 5 countries\n",
        "    top_5_countries = df['Country'].value_counts().head(5)\n",
        "    fig1 = px.bar(\n",
        "        x=top_5_countries.index,\n",
        "        y=top_5_countries.values,\n",
        "        labels={'x': 'Country', 'y': 'Customer Count'},\n",
        "        title=\"Top 5 Countries by Customer Count\"\n",
        "    )\n",
        "    st.plotly_chart(fig1)\n",
        "\n",
        "    # Bar chart: Top 5 cities\n",
        "    top_5_cities = df['City'].value_counts().head(5)\n",
        "    fig2 = px.bar(\n",
        "        x=top_5_cities.index,\n",
        "        y=top_5_cities.values,\n",
        "        labels={'x': 'City', 'y': 'Customer Count'},\n",
        "        title=\"Top 5 Cities by Customer Count\"\n",
        "    )\n",
        "    st.plotly_chart(fig2)\n",
        "\n",
        "    # Pie chart: Country distribution (Top 5 + Others)\n",
        "    country_counts = df['Country'].value_counts()\n",
        "    top_n = 5\n",
        "    top_countries = country_counts.head(top_n)\n",
        "    others_count = country_counts.iloc[top_n:].sum()\n",
        "    pie_data = pd.concat([\n",
        "        top_countries,\n",
        "        pd.Series([others_count], index=['Others'])\n",
        "    ])\n",
        "    fig3 = px.pie(\n",
        "        names=pie_data.index,\n",
        "        values=pie_data.values,\n",
        "        title=f\"Customer Distribution by Country (Top {top_n} + Others)\"\n",
        "    )\n",
        "    st.plotly_chart(fig3)\n",
        "\n",
        "    # Pie chart: Email domains\n",
        "    df['Email Domain'] = df['Email'].apply(lambda x: x.split('@')[1] if pd.notna(x) else 'Unknown')\n",
        "    email_domain_counts = df['Email Domain'].value_counts().head(5)\n",
        "    fig4 = px.pie(\n",
        "        names=email_domain_counts.index,\n",
        "        values=email_domain_counts.values,\n",
        "        title=\"Customer Distribution by Email Domain\"\n",
        "    )\n",
        "    st.plotly_chart(fig4)\n",
        "\n",
        "    # Horizontal bar: Top 10 companies\n",
        "    top_10_companies = df['Company'].value_counts().head(10)\n",
        "    fig5 = px.bar(\n",
        "        y=top_10_companies.index,\n",
        "        x=top_10_companies.values,\n",
        "        orientation='h',\n",
        "        labels={'x': 'Customer Count', 'y': 'Company'},\n",
        "        title=\"Top 10 Companies by Customer Count\"\n",
        "    )\n",
        "    st.plotly_chart(fig5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOJ8oM03EXmP",
        "outputId": "7de4c2d7-4058-4e95-b42b-03f5763204ea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "\n",
        "# Set your ngrok authtoken\n",
        "!2zarR0Ln43mhGvAsMJ0EhKy9P1c_6jj4ELrgSiLKCKtrfB6CK  # Replace with your actual authtoken\n",
        "\n",
        "# Start Streamlit server\n",
        "process = subprocess.Popen(['streamlit', 'run', 'app.py', '--server.port', '8501'])\n",
        "\n",
        "# Create a public URL with ngrok\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Streamlit app is running at: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "UpQ2G2N-IdQW",
        "outputId": "9a7ee466-0ab6-4fe5-9573-21f08e9a5580"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: 2zarR0Ln43mhGvAsMJ0EhKy9P1c_6jj4ELrgSiLKCKtrfB6CK: command not found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pyngrok.process.ngrok:t=2025-07-08T13:08:35+0000 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-07-08T13:08:35+0000 lvl=eror msg=\"session closing\" obj=tunnels.session err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-07-08T13:08:35+0000 lvl=eror msg=\"terminating with error\" obj=app err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
            "CRITICAL:pyngrok.process.ngrok:t=2025-07-08T13:08:35+0000 lvl=crit msg=\"command failed\" err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PyngrokNgrokError",
          "evalue": "The ngrok process errored on start: authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-12-1310327727.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Create a public URL with ngrok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8501\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Streamlit app is running at: {public_url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Opening tunnel named: {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m     \u001b[0mapi_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ngrok_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Creating tunnel with options: {options}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mget_ngrok_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0minstall_ngrok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36mget_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_current_processes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngrok_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_start_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36m_start_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartup_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m             raise PyngrokNgrokError(f\"The ngrok process errored on start: {ngrok_process.startup_error}.\",\n\u001b[0m\u001b[1;32m    448\u001b[0m                                     \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                                     ngrok_process.startup_error)\n",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m: The ngrok process errored on start: authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install streamlit pandas numpy matplotlib seaborn plotly pyngrok\n",
        "\n",
        "# Set ngrok authtoken\n",
        "!ngrok authtoken 2zarR0Ln43mhGvAsMJ0EhKy9P1c_6jj4ELrgSiLKCKtrfB6CK\n",
        "\n",
        "# Write the Streamlit app code (app.py)\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "from pathlib import Path\n",
        "\n",
        "# Set page config\n",
        "st.set_page_config(page_title=\"Customer Manager & Analyzer\", layout=\"wide\")\n",
        "\n",
        "# Load and clean data\n",
        "@st.cache_data\n",
        "def load_and_clean_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df = df.drop_duplicates()\n",
        "    df = df.dropna(subset=['First Name', 'Email'])\n",
        "    df = df.drop(columns=['Index', 'Subscription Date'], errors='ignore')\n",
        "    return df\n",
        "\n",
        "# File path\n",
        "file_path = \"/content/customers-100.csv\"\n",
        "try:\n",
        "    df = load_and_clean_data(file_path)\n",
        "except FileNotFoundError:\n",
        "    st.error(\"customers-100.csv not found! Please upload the file.\")\n",
        "    st.stop()\n",
        "\n",
        "# Sidebar for navigation\n",
        "st.sidebar.title(\"Navigation\")\n",
        "view = st.sidebar.radio(\"Select View\", [\"Overview\", \"Table\", \"Stats\"])\n",
        "\n",
        "# Overview View\n",
        "if view == \"Overview\":\n",
        "    st.title(\"Customer Data Overview\")\n",
        "    st.write(\"Summary statistics of the cleaned customer dataset.\")\n",
        "    total_customers = len(df)\n",
        "    unique_countries = df['Country'].nunique()\n",
        "    most_common_country = df['Country'].mode()[0]\n",
        "    top_3_cities = df['City'].value_counts().head(3).index.tolist()\n",
        "    top_5_companies = df['Company'].value_counts().head(5).index.tolist()\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        st.metric(\"Total Customers\", total_customers)\n",
        "        st.metric(\"Unique Countries\", unique_countries)\n",
        "    with col2:\n",
        "        st.metric(\"Most Common Country\", most_common_country)\n",
        "        st.write(\"Top 3 Cities:\", \", \".join(top_3_cities))\n",
        "        st.write(\"Top 5 Companies:\", \", \".join(top_5_companies))\n",
        "\n",
        "# Table View\n",
        "elif view == \"Table\":\n",
        "    st.title(\"Editable Customer Table\")\n",
        "    st.write(\"Edit the dataset below and download the updated version.\")\n",
        "    edited_df = st.data_editor(df, num_rows=\"dynamic\")\n",
        "    if st.button(\"Export Edited Data\"):\n",
        "        edited_df.to_csv(\"edited_customers.csv\", index=False)\n",
        "        st.download_button(\n",
        "            label=\"Download Edited CSV\",\n",
        "            data=Path(\"edited_customers.csv\").read_bytes(),\n",
        "            file_name=\"edited_customers.csv\",\n",
        "            mime=\"text/csv\"\n",
        "        )\n",
        "\n",
        "# Stats View\n",
        "elif view == \"Stats\":\n",
        "    st.title(\"Customer Data Visualizations\")\n",
        "    st.write(\"Graphical insights into customer distribution.\")\n",
        "    top_5_countries = df['Country'].value_counts().head(5)\n",
        "    fig1 = px.bar(x=top_5_countries.index, y=top_5_countries.values,\n",
        "                  labels={'x': 'Country', 'y': 'Customer Count'}, title=\"Top 5 Countries by Customer Count\")\n",
        "    st.plotly_chart(fig1)\n",
        "    top_5_cities = df['City'].value_counts().head(5)\n",
        "    fig2 = px.bar(x=top_5_cities.index, y=top_5_cities.values,\n",
        "                  labels={'x': 'City', 'y': 'Customer Count'}, title=\"Top 5 Cities by Customer Count\")\n",
        "    st.plotly_chart(fig2)\n",
        "    country_counts = df['Country'].value_counts()\n",
        "    top_n = 5\n",
        "    top_countries = country_counts.head(top_n)\n",
        "    others_count = country_counts.iloc[top_n:].sum()\n",
        "    pie_data = pd.concat([top_countries, pd.Series([others_count], index=['Others'])])\n",
        "    fig3 = px.pie(names=pie_data.index, values=pie_data.values,\n",
        "                  title=f\"Customer Distribution by Country (Top {top_n} + Others)\")\n",
        "    st.plotly_chart(fig3)\n",
        "    df['Email Domain'] = df['Email'].apply(lambda x: x.split('@')[1] if pd.notna(x) else 'Unknown')\n",
        "    email_domain_counts = df['Email Domain'].value_counts().head(5)\n",
        "    fig4 = px.pie(names=email_domain_counts.index, values=email_domain_counts.values,\n",
        "                  title=\"Customer Distribution by Email Domain\")\n",
        "    st.plotly_chart(fig4)\n",
        "    top_10_companies = df['Company'].value_counts().head(10)\n",
        "    fig5 = px.bar(y=top_10_companies.index, x=top_10_companies.values, orientation='h',\n",
        "                  labels={'x': 'Customer Count', 'y': 'Company'}, title=\"Top 10 Companies by Customer Count\")\n",
        "    st.plotly_chart(fig5)\n",
        "\n",
        "# Start Streamlit server and ngrok\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "\n",
        "# Start Streamlit server\n",
        "process = subprocess.Popen(['streamlit', 'run', 'app.py', '--server.port', '8501'])\n",
        "\n",
        "# Create a public URL with ngrok\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Streamlit app is running at: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkWcCVJbKXCR",
        "outputId": "b9904505-72f6-4ea5-a9d0-6cb6aae662dd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.46.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.11)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.45.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.6.15)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Line magic function `%%writefile` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "from pathlib import Path\n",
        "\n",
        "# Set page config\n",
        "st.set_page_config(page_title=\"Customer Manager & Analyzer\", layout=\"wide\")\n",
        "\n",
        "# Load and clean data\n",
        "@st.cache_data\n",
        "def load_and_clean_data(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    df = df.drop_duplicates()\n",
        "    df = df.dropna(subset=['First Name', 'Email'])\n",
        "    df = df.drop(columns=['Index', 'Subscription Date'], errors='ignore')\n",
        "    return df\n",
        "\n",
        "# File path\n",
        "file_path = \"customers-100.csv\"\n",
        "try:\n",
        "    df = load_and_clean_data(file_path)\n",
        "except FileNotFoundError:\n",
        "    st.error(\"customers-100.csv not found! Please upload the file.\")\n",
        "    st.stop()\n",
        "\n",
        "# Sidebar for navigation\n",
        "st.sidebar.title(\"Navigation\")\n",
        "view = st.sidebar.radio(\"Select View\", [\"Overview\", \"Table\", \"Stats\"])\n",
        "\n",
        "# Overview View\n",
        "if view == \"Overview\":\n",
        "    st.title(\"Customer Data Overview\")\n",
        "    st.write(\"Summary statistics of the cleaned customer dataset.\")\n",
        "    total_customers = len(df)\n",
        "    unique_countries = df['Country'].nunique()\n",
        "    most_common_country = df['Country'].mode()[0]\n",
        "    top_3_cities = df['City'].value_counts().head(3).index.tolist()\n",
        "    top_5_companies = df['Company'].value_counts().head(5).index.tolist()\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        st.metric(\"Total Customers\", total_customers)\n",
        "        st.metric(\"Unique Countries\", unique_countries)\n",
        "    with col2:\n",
        "        st.metric(\"Most Common Country\", most_common_country)\n",
        "        st.write(\"Top 3 Cities:\", \", \".join(top_3_cities))\n",
        "        st.write(\"Top 5 Companies:\", \", \".join(top_5_companies))\n",
        "\n",
        "# Table View\n",
        "elif view == \"Table\":\n",
        "    st.title(\"Editable Customer Table\")\n",
        "    st.write(\"Edit the dataset below and download the updated version.\")\n",
        "    edited_df = st.data_editor(df, num_rows=\"dynamic\")\n",
        "    if st.button(\"Export Edited Data\"):\n",
        "        edited_df.to_csv(\"edited_customers.csv\", index=False)\n",
        "        st.download_button(\n",
        "            label=\"Download Edited CSV\",\n",
        "            data=Path(\"edited_customers.csv\").read_bytes(),\n",
        "            file_name=\"edited_customers.csv\",\n",
        "            mime=\"text/csv\"\n",
        "        )\n",
        "\n",
        "# Stats View\n",
        "elif view == \"Stats\":\n",
        "    st.title(\"Customer Data Visualizations\")\n",
        "    st.write(\"Graphical insights into customer distribution.\")\n",
        "\n",
        "    # Bar chart: Top 5 countries\n",
        "    top_5_countries = df['Country'].value_counts().head(5)\n",
        "    fig1 = px.bar(x=top_5_countries.index, y=top_5_countries.values,\n",
        "                  labels={'x': 'Country', 'y': 'Customer Count'}, title=\"Top 5 Countries by Customer Count\")\n",
        "    st.plotly_chart(fig1)\n",
        "\n",
        "    # Bar chart: Top 5 cities\n",
        "    top_5_cities = df['City'].value_counts().head(5)\n",
        "    fig2 = px.bar(x=top_5_cities.index, y=top_5_cities.values,\n",
        "                  labels={'x': 'City', 'y': 'Customer Count'}, title=\"Top 5 Cities by Customer Count\")\n",
        "    st.plotly_chart(fig2)\n",
        "\n",
        "    # Pie chart: Country distribution (Top 5 + Others)\n",
        "    country_counts = df['Country'].value_counts()\n",
        "    top_n = 5\n",
        "    top_countries = country_counts.head(top_n)\n",
        "    others_count = country_counts.iloc[top_n:].sum()\n",
        "    pie_data = pd.concat([top_countries, pd.Series([others_count], index=['Others'])])\n",
        "    fig3 = px.pie(names=pie_data.index, values=pie_data.values,\n",
        "                  title=f\"Customer Distribution by Country (Top {top_n} + Others)\")\n",
        "    st.plotly_chart(fig3)\n",
        "\n",
        "    # Pie chart: Email domains\n",
        "    df['Email Domain'] = df['Email'].apply(lambda x: x.split('@')[1] if pd.notna(x) else 'Unknown')\n",
        "    email_domain_counts = df['Email Domain'].value_counts().head(5)\n",
        "    fig4 = px.pie(names=email_domain_counts.index, values=email_domain_counts.values,\n",
        "                  title=\"Customer Distribution by Email Domain\")\n",
        "    st.plotly_chart(fig4)\n",
        "\n",
        "    # Horizontal bar: Top 10 companies\n",
        "    top_10_companies = df['Company'].value_counts().head(10)\n",
        "    fig5 = px.bar(y=top_10_companies.index, x=top_10_companies.values, orientation='h',\n",
        "                  labels={'x': 'Customer Count', 'y': 'Company'}, title=\"Top 10 Companies by Customer Count\")\n",
        "    st.plotly_chart(fig5)\n",
        "\n",
        "    # Optional: Stacked bar chart (Country + Email Availability)\n",
        "    email_availability = df.copy()\n",
        "    email_availability['Email Status'] = email_availability['Email'].isna().map({True: 'Missing Email', False: 'Has Email'})\n",
        "    stacked_data = email_availability.groupby(['Country', 'Email Status']).size().unstack(fill_value=0)\n",
        "    fig6 = px.bar(stacked_data, barmode='stack',\n",
        "                  title=\"Customers by Country and Email Availability\",\n",
        "                  labels={'value': 'Customer Count', 'Country': 'Country'})\n",
        "    st.plotly_chart(fig6)\n",
        "\n",
        "    # Optional: Box plot (Company Name Length)\n",
        "    df['Company Name Length'] = df['Company'].str.len()\n",
        "    fig7 = px.box(df, y='Company Name Length',\n",
        "                  title=\"Distribution of Company Name Lengths\")\n",
        "    st.plotly_chart(fig7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFNhUaLmShsR",
        "outputId": "c323d14b-d783-4548-8d27-37fd31351dc0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "\n",
        "# Start Streamlit server in the background\n",
        "process = subprocess.Popen(['streamlit', 'run', 'app.py', '--server.port', '8501'])\n",
        "\n",
        "# Create a public URL with ngrok\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Streamlit app is running at: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV6-2Kw9Sumy",
        "outputId": "b48c2be0-bf82-4779-f6eb-198457ca832e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app is running at: NgrokTunnel: \"https://302d3ab5781d.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6fxpk3drUU-",
        "outputId": "22e94247-884c-469a-d740-59696ec4e67a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import streamlit as st\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "import plotly.express as px\n",
            "from pathlib import Path\n",
            "\n",
            "# Set page config\n",
            "st.set_page_config(page_title=\"Customer Manager & Analyzer\", layout=\"wide\")\n",
            "\n",
            "# Load and clean data\n",
            "@st.cache_data\n",
            "def load_and_clean_data(file_path):\n",
            "    df = pd.read_csv(file_path)\n",
            "    df = df.drop_duplicates()\n",
            "    df = df.dropna(subset=['First Name', 'Email'])\n",
            "    df = df.drop(columns=['Index', 'Subscription Date'], errors='ignore')\n",
            "    return df\n",
            "\n",
            "# File path\n",
            "file_path = \"customers-100.csv\"\n",
            "try:\n",
            "    df = load_and_clean_data(file_path)\n",
            "except FileNotFoundError:\n",
            "    st.error(\"customers-100.csv not found! Please upload the file.\")\n",
            "    st.stop()\n",
            "\n",
            "# Sidebar for navigation\n",
            "st.sidebar.title(\"Navigation\")\n",
            "view = st.sidebar.radio(\"Select View\", [\"Overview\", \"Table\", \"Stats\"])\n",
            "\n",
            "# Overview View\n",
            "if view == \"Overview\":\n",
            "    st.title(\"Customer Data Overview\")\n",
            "    st.write(\"Summary statistics of the cleaned customer dataset.\")\n",
            "    total_customers = len(df)\n",
            "    unique_countries = df['Country'].nunique()\n",
            "    most_common_country = df['Country'].mode()[0]\n",
            "    top_3_cities = df['City'].value_counts().head(3).index.tolist()\n",
            "    top_5_companies = df['Company'].value_counts().head(5).index.tolist()\n",
            "    col1, col2 = st.columns(2)\n",
            "    with col1:\n",
            "        st.metric(\"Total Customers\", total_customers)\n",
            "        st.metric(\"Unique Countries\", unique_countries)\n",
            "    with col2:\n",
            "        st.metric(\"Most Common Country\", most_common_country)\n",
            "        st.write(\"Top 3 Cities:\", \", \".join(top_3_cities))\n",
            "        st.write(\"Top 5 Companies:\", \", \".join(top_5_companies))\n",
            "\n",
            "# Table View\n",
            "elif view == \"Table\":\n",
            "    st.title(\"Editable Customer Table\")\n",
            "    st.write(\"Edit the dataset below and download the updated version.\")\n",
            "    edited_df = st.data_editor(df, num_rows=\"dynamic\")\n",
            "    if st.button(\"Export Edited Data\"):\n",
            "        edited_df.to_csv(\"edited_customers.csv\", index=False)\n",
            "        st.download_button(\n",
            "            label=\"Download Edited CSV\",\n",
            "            data=Path(\"edited_customers.csv\").read_bytes(),\n",
            "            file_name=\"edited_customers.csv\",\n",
            "            mime=\"text/csv\"\n",
            "        )\n",
            "\n",
            "# Stats View\n",
            "elif view == \"Stats\":\n",
            "    st.title(\"Customer Data Visualizations\")\n",
            "    st.write(\"Graphical insights into customer distribution.\")\n",
            "    \n",
            "    # Bar chart: Top 5 countries\n",
            "    top_5_countries = df['Country'].value_counts().head(5)\n",
            "    fig1 = px.bar(x=top_5_countries.index, y=top_5_countries.values,\n",
            "                  labels={'x': 'Country', 'y': 'Customer Count'}, title=\"Top 5 Countries by Customer Count\")\n",
            "    st.plotly_chart(fig1)\n",
            "    \n",
            "    # Bar chart: Top 5 cities\n",
            "    top_5_cities = df['City'].value_counts().head(5)\n",
            "    fig2 = px.bar(x=top_5_cities.index, y=top_5_cities.values,\n",
            "                  labels={'x': 'City', 'y': 'Customer Count'}, title=\"Top 5 Cities by Customer Count\")\n",
            "    st.plotly_chart(fig2)\n",
            "    \n",
            "    # Pie chart: Country distribution (Top 5 + Others)\n",
            "    country_counts = df['Country'].value_counts()\n",
            "    top_n = 5\n",
            "    top_countries = country_counts.head(top_n)\n",
            "    others_count = country_counts.iloc[top_n:].sum()\n",
            "    pie_data = pd.concat([top_countries, pd.Series([others_count], index=['Others'])])\n",
            "    fig3 = px.pie(names=pie_data.index, values=pie_data.values,\n",
            "                  title=f\"Customer Distribution by Country (Top {top_n} + Others)\")\n",
            "    st.plotly_chart(fig3)\n",
            "    \n",
            "    # Pie chart: Email domains\n",
            "    df['Email Domain'] = df['Email'].apply(lambda x: x.split('@')[1] if pd.notna(x) else 'Unknown')\n",
            "    email_domain_counts = df['Email Domain'].value_counts().head(5)\n",
            "    fig4 = px.pie(names=email_domain_counts.index, values=email_domain_counts.values,\n",
            "                  title=\"Customer Distribution by Email Domain\")\n",
            "    st.plotly_chart(fig4)\n",
            "    \n",
            "    # Horizontal bar: Top 10 companies\n",
            "    top_10_companies = df['Company'].value_counts().head(10)\n",
            "    fig5 = px.bar(y=top_10_companies.index, x=top_10_companies.values, orientation='h',\n",
            "                  labels={'x': 'Customer Count', 'y': 'Company'}, title=\"Top 10 Companies by Customer Count\")\n",
            "    st.plotly_chart(fig5)\n",
            "    \n",
            "    # Optional: Stacked bar chart (Country + Email Availability)\n",
            "    email_availability = df.copy()\n",
            "    email_availability['Email Status'] = email_availability['Email'].isna().map({True: 'Missing Email', False: 'Has Email'})\n",
            "    stacked_data = email_availability.groupby(['Country', 'Email Status']).size().unstack(fill_value=0)\n",
            "    fig6 = px.bar(stacked_data, barmode='stack',\n",
            "                  title=\"Customers by Country and Email Availability\",\n",
            "                  labels={'value': 'Customer Count', 'Country': 'Country'})\n",
            "    st.plotly_chart(fig6)\n",
            "    \n",
            "    # Optional: Box plot (Company Name Length)\n",
            "    df['Company Name Length'] = df['Company'].str.len()\n",
            "    fig7 = px.box(df, y='Company Name Length',\n",
            "                  title=\"Distribution of Company Name Lengths\")\n",
            "    st.plotly_chart(fig7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('customers-100.csv')\n",
        "print(\"Dataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nMissing Emails:\", df['Email'].isna().sum())\n",
        "print(\"\\nCompany Column Sample:\", df['Company'].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHxZbxBIrhtu",
        "outputId": "ccb7cba1-7e86-42a1-d5a0-60f6467d623f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 102 entries, 0 to 101\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   Index              102 non-null    int64 \n",
            " 1   Customer Id        102 non-null    object\n",
            " 2   First Name         101 non-null    object\n",
            " 3   Last Name          102 non-null    object\n",
            " 4   Company            101 non-null    object\n",
            " 5   City               102 non-null    object\n",
            " 6   Country            102 non-null    object\n",
            " 7   Phone 1            102 non-null    object\n",
            " 8   Phone 2            102 non-null    object\n",
            " 9   Email              101 non-null    object\n",
            " 10  Subscription Date  102 non-null    object\n",
            " 11  Website            102 non-null    object\n",
            "dtypes: int64(1), object(11)\n",
            "memory usage: 9.7+ KB\n",
            "None\n",
            "\n",
            "Missing Emails: 1\n",
            "\n",
            "Company Column Sample: 0                    Rasmussen Group\n",
            "1                        Vega-Gentry\n",
            "2                      Murillo-Perry\n",
            "3    Dominguez, Mcmillan and Donovan\n",
            "4           Martin, Lang and Andrade\n",
            "Name: Company, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ~/.streamlit/cache"
      ],
      "metadata": {
        "id": "ve3odbbws2bX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "from pathlib import Path\n",
        "\n",
        "# Set page config\n",
        "st.set_page_config(page_title=\"Customer Manager & Analyzer\", layout=\"wide\")\n",
        "\n",
        "# Load and clean data\n",
        "@st.cache_data\n",
        "def load_and_clean_data(file_path):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        df = df.drop_duplicates()\n",
        "        df = df.dropna(subset=['First Name', 'Email'])\n",
        "        df = df.drop(columns=['Index', 'Subscription Date'], errors='ignore')\n",
        "        st.write(\"Data loaded and cleaned successfully.\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading data: {e}\")\n",
        "        return None\n",
        "\n",
        "# File path\n",
        "file_path = \"customers-100.csv\"\n",
        "df = load_and_clean_data(file_path)\n",
        "if df is None:\n",
        "    st.stop()\n",
        "\n",
        "# Sidebar for navigation\n",
        "st.sidebar.title(\"Navigation\")\n",
        "view = st.sidebar.radio(\"Select View\", [\"Overview\", \"Table\", \"Stats\"])\n",
        "\n",
        "# Clear cache button\n",
        "if st.sidebar.button(\"Clear Cache\"):\n",
        "    st.cache_data.clear()\n",
        "    st.write(\"Cache cleared. Please refresh the page.\")\n",
        "\n",
        "# Overview View\n",
        "if view == \"Overview\":\n",
        "    st.title(\"Customer Data Overview\")\n",
        "    st.write(\"Summary statistics of the cleaned customer dataset.\")\n",
        "    total_customers = len(df)\n",
        "    unique_countries = df['Country'].nunique()\n",
        "    most_common_country = df['Country'].mode()[0]\n",
        "    top_3_cities = df['City'].value_counts().head(3).index.tolist()\n",
        "    top_5_companies = df['Company'].value_counts().head(5).index.tolist()\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        st.metric(\"Total Customers\", total_customers)\n",
        "        st.metric(\"Unique Countries\", unique_countries)\n",
        "    with col2:\n",
        "        st.metric(\"Most Common Country\", most_common_country)\n",
        "        st.write(\"Top 3 Cities:\", \", \".join(top_3_cities))\n",
        "        st.write(\"Top 5 Companies:\", \", \".join(top_5_companies))\n",
        "\n",
        "# Table View\n",
        "elif view == \"Table\":\n",
        "    st.title(\"Editable Customer Table\")\n",
        "    st.write(\"Edit the dataset below and download the updated version.\")\n",
        "    edited_df = st.data_editor(df, num_rows=\"dynamic\")\n",
        "    if st.button(\"Export Edited Data\"):\n",
        "        edited_df.to_csv(\"edited_customers.csv\", index=False)\n",
        "        st.download_button(\n",
        "            label=\"Download Edited CSV\",\n",
        "            data=Path(\"edited_customers.csv\").read_bytes(),\n",
        "            file_name=\"edited_customers.csv\",\n",
        "            mime=\"text/csv\"\n",
        "        )\n",
        "\n",
        "# Stats View\n",
        "elif view == \"Stats\":\n",
        "    st.title(\"Customer Data Visualizations\")\n",
        "    st.write(\"Graphical insights into customer distribution.\")\n",
        "\n",
        "    try:\n",
        "        # Bar chart: Top 5 countries\n",
        "        st.write(\"Rendering: Top 5 Countries Bar Chart\")\n",
        "        top_5_countries = df['Country'].value_counts().head(5)\n",
        "        fig1 = px.bar(x=top_5_countries.index, y=top_5_countries.values,\n",
        "                      labels={'x': 'Country', 'y': 'Customer Count'}, title=\"Top 5 Countries by Customer Count\")\n",
        "        st.plotly_chart(fig1)\n",
        "\n",
        "        # Bar chart: Top 5 cities\n",
        "        st.write(\"Rendering: Top 5 Cities Bar Chart\")\n",
        "        top_5_cities = df['City'].value_counts().head(5)\n",
        "        fig2 = px.bar(x=top_5_cities.index, y=top_5_cities.values,\n",
        "                      labels={'x': 'City', 'y': 'Customer Count'}, title=\"Top 5 Cities by Customer Count\")\n",
        "        st.plotly_chart(fig2)\n",
        "\n",
        "        # Pie chart: Country distribution (Top 5 + Others)\n",
        "        st.write(\"Rendering: Country Distribution Pie Chart\")\n",
        "        country_counts = df['Country'].value_counts()\n",
        "        top_n = 5\n",
        "        top_countries = country_counts.head(top_n)\n",
        "        others_count = country_counts.iloc[top_n:].sum()\n",
        "        pie_data = pd.concat([top_countries, pd.Series([others_count], index=['Others'])])\n",
        "        fig3 = px.pie(names=pie_data.index, values=pie_data.values,\n",
        "                      title=f\"Customer Distribution by Country (Top {top_n} + Others)\")\n",
        "        st.plotly_chart(fig3)\n",
        "\n",
        "        # Pie chart: Email domains\n",
        "        st.write(\"Rendering: Email Domains Pie Chart\")\n",
        "        df['Email Domain'] = df['Email'].apply(lambda x: x.split('@')[1] if pd.notna(x) else 'Unknown')\n",
        "        email_domain_counts = df['Email Domain'].value_counts().head(5)\n",
        "        fig4 = px.pie(names=email_domain_counts.index, values=email_domain_counts.values,\n",
        "                      title=\"Customer Distribution by Email Domain\")\n",
        "        st.plotly_chart(fig4)\n",
        "\n",
        "        # Horizontal bar: Top 10 companies\n",
        "        st.write(\"Rendering: Top 10 Companies Horizontal Bar Chart\")\n",
        "        top_10_companies = df['Company'].value_counts().head(10)\n",
        "        fig5 = px.bar(y=top_10_companies.index, x=top_10_companies.values, orientation='h',\n",
        "                      labels={'x': 'Customer Count', 'y': 'Company'}, title=\"Top 10 Companies by Customer Count\")\n",
        "        st.plotly_chart(fig5)\n",
        "\n",
        "        # Optional: Stacked bar chart (Country + Email Availability)\n",
        "        st.write(\"Rendering: Stacked Bar Chart (Country + Email Availability)\")\n",
        "        email_availability = df.copy()\n",
        "        email_availability['Email Status'] = email_availability['Email'].isna().map({True: 'Missing Email', False: 'Has Email'})\n",
        "        stacked_data = email_availability.groupby(['Country', 'Email Status']).size().unstack(fill_value=0)\n",
        "        if stacked_data.empty:\n",
        "            st.warning(\"No data available for Stacked Bar Chart. Check 'Email' column.\")\n",
        "        else:\n",
        "            fig6 = px.bar(stacked_data, barmode='stack',\n",
        "                          title=\"Customers by Country and Email Availability\",\n",
        "                          labels={'value': 'Customer Count', 'Country': 'Country'})\n",
        "            st.plotly_chart(fig6)\n",
        "\n",
        "        # Optional: Box plot (Company Name Length)\n",
        "        st.write(\"Rendering: Box Plot (Company Name Length)\")\n",
        "        df['Company Name Length'] = df['Company'].str.len()\n",
        "        if df['Company Name Length'].isna().all():\n",
        "            st.warning(\"No valid company name lengths for Box Plot. Check 'Company' column.\")\n",
        "        else:\n",
        "            fig7 = px.box(df, y='Company Name Length',\n",
        "                          title=\"Distribution of Company Name Lengths\")\n",
        "            st.plotly_chart(fig7)\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error rendering visualizations: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXrrNrbBs6xG",
        "outputId": "ba488cd7-190e-4b15-e8a2-2865f7134efe"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-08 15:42:25.942 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.945 No runtime found, using MemoryCacheStorageManager\n",
            "2025-07-08 15:42:25.950 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.951 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.953 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.954 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.956 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.957 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.958 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.960 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.961 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.962 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.963 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.965 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.966 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.967 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.968 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.969 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.972 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.973 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.974 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.975 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.976 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.977 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.982 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.984 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.985 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.987 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.988 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.989 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.990 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.991 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.992 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.993 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.994 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.996 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.996 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.997 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.998 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.999 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:25.999 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:26.000 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:26.001 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:26.001 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:26.002 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:26.003 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:26.004 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:26.004 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "from pathlib import Path\n",
        "\n",
        "# Set page config\n",
        "st.set_page_config(page_title=\"Customer Manager & Analyzer\", layout=\"wide\")\n",
        "\n",
        "# Load and clean data\n",
        "@st.cache_data\n",
        "def load_and_clean_data(file_path):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        df = df.drop_duplicates()\n",
        "        df = df.dropna(subset=['First Name', 'Email'])\n",
        "        df = df.drop(columns=['Index', 'Subscription Date'], errors='ignore')\n",
        "        st.write(\"Data loaded and cleaned successfully.\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading data: {e}\")\n",
        "        return None\n",
        "\n",
        "# File path\n",
        "file_path = \"customers-100.csv\"\n",
        "df = load_and_clean_data(file_path)\n",
        "if df is None:\n",
        "    st.stop()\n",
        "\n",
        "# Sidebar for navigation\n",
        "st.sidebar.title(\"Navigation\")\n",
        "view = st.sidebar.radio(\"Select View\", [\"Overview\", \"Table\", \"Stats\"])\n",
        "\n",
        "# Clear cache button\n",
        "if st.sidebar.button(\"Clear Cache\"):\n",
        "    st.cache_data.clear()\n",
        "    st.write(\"Cache cleared. Please refresh the page.\")\n",
        "\n",
        "# Overview View\n",
        "if view == \"Overview\":\n",
        "    st.title(\"Customer Data Overview\")\n",
        "    st.write(\"Summary statistics of the cleaned customer dataset.\")\n",
        "    total_customers = len(df)\n",
        "    unique_countries = df['Country'].nunique()\n",
        "    most_common_country = df['Country'].mode()[0]\n",
        "    top_3_cities = df['City'].value_counts().head(3).index.tolist()\n",
        "    top_5_companies = df['Company'].value_counts().head(5).index.tolist()\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        st.metric(\"Total Customers\", total_customers)\n",
        "        st.metric(\"Unique Countries\", unique_countries)\n",
        "    with col2:\n",
        "        st.metric(\"Most Common Country\", most_common_country)\n",
        "        st.write(\"Top 3 Cities:\", \", \".join(top_3_cities))\n",
        "        st.write(\"Top 5 Companies:\", \", \".join(top_5_companies))\n",
        "\n",
        "# Table View\n",
        "elif view == \"Table\":\n",
        "    st.title(\"Editable Customer Table\")\n",
        "    st.write(\"Edit the dataset below and download the updated version.\")\n",
        "    edited_df = st.data_editor(df, num_rows=\"dynamic\")\n",
        "    if st.button(\"Export Edited Data\"):\n",
        "        edited_df.to_csv(\"edited_customers.csv\", index=False)\n",
        "        st.download_button(\n",
        "            label=\"Download Edited CSV\",\n",
        "            data=Path(\"edited_customers.csv\").read_bytes(),\n",
        "            file_name=\"edited_customers.csv\",\n",
        "            mime=\"text/csv\"\n",
        "        )\n",
        "\n",
        "# Stats View\n",
        "elif view == \"Stats\":\n",
        "    st.title(\"Customer Data Visualizations\")\n",
        "    st.write(\"Graphical insights into customer distribution.\")\n",
        "\n",
        "    try:\n",
        "        # Bar chart: Top 5 countries\n",
        "        st.write(\"Rendering: Top 5 Countries Bar Chart\")\n",
        "        top_5_countries = df['Country'].value_counts().head(5)\n",
        "        fig1 = px.bar(x=top_5_countries.index, y=top_5_countries.values,\n",
        "                      labels={'x': 'Country', 'y': 'Customer Count'}, title=\"Top 5 Countries by Customer Count\")\n",
        "        st.plotly_chart(fig1)\n",
        "\n",
        "        # Bar chart: Top 5 cities\n",
        "        st.write(\"Rendering: Top 5 Cities Bar Chart\")\n",
        "        top_5_cities = df['City'].value_counts().head(5)\n",
        "        fig2 = px.bar(x=top_5_cities.index, y=top_5_cities.values,\n",
        "                      labels={'x': 'City', 'y': 'Customer Count'}, title=\"Top 5 Cities by Customer Count\")\n",
        "        st.plotly_chart(fig2)\n",
        "\n",
        "        # Pie chart: Country distribution (Top 5 + Others)\n",
        "        st.write(\"Rendering: Country Distribution Pie Chart\")\n",
        "        country_counts = df['Country'].value_counts()\n",
        "        top_n = 5\n",
        "        top_countries = country_counts.head(top_n)\n",
        "        others_count = country_counts.iloc[top_n:].sum()\n",
        "        pie_data = pd.concat([top_countries, pd.Series([others_count], index=['Others'])])\n",
        "        fig3 = px.pie(names=pie_data.index, values=pie_data.values,\n",
        "                      title=f\"Customer Distribution by Country (Top {top_n} + Others)\")\n",
        "        st.plotly_chart(fig3)\n",
        "\n",
        "        # Pie chart: Email domains\n",
        "        st.write(\"Rendering: Email Domains Pie Chart\")\n",
        "        df['Email Domain'] = df['Email'].apply(lambda x: x.split('@')[1] if pd.notna(x) else 'Unknown')\n",
        "        email_domain_counts = df['Email Domain'].value_counts().head(5)\n",
        "        fig4 = px.pie(names=email_domain_counts.index, values=email_domain_counts.values,\n",
        "                      title=\"Customer Distribution by Email Domain\")\n",
        "        st.plotly_chart(fig4)\n",
        "\n",
        "        # Horizontal bar: Top 10 companies\n",
        "        st.write(\"Rendering: Top 10 Companies Horizontal Bar Chart\")\n",
        "        top_10_companies = df['Company'].value_counts().head(10)\n",
        "        fig5 = px.bar(y=top_10_companies.index, x=top_10_companies.values, orientation='h',\n",
        "                      labels={'x': 'Customer Count', 'y': 'Company'}, title=\"Top 10 Companies by Customer Count\")\n",
        "        st.plotly_chart(fig5)\n",
        "\n",
        "        # Optional: Stacked bar chart (Country + Email Availability)\n",
        "        st.write(\"Rendering: Stacked Bar Chart (Country + Email Availability)\")\n",
        "        email_availability = df.copy()\n",
        "        email_availability['Email Status'] = email_availability['Email'].isna().map({True: 'Missing Email', False: 'Has Email'})\n",
        "        stacked_data = email_availability.groupby(['Country', 'Email Status']).size().unstack(fill_value=0)\n",
        "        if stacked_data.empty:\n",
        "            st.warning(\"No data available for Stacked Bar Chart. Check 'Email' column.\")\n",
        "        else:\n",
        "            fig6 = px.bar(stacked_data, barmode='stack',\n",
        "                          title=\"Customers by Country and Email Availability\",\n",
        "                          labels={'value': 'Customer Count', 'Country': 'Country'})\n",
        "            st.plotly_chart(fig6)\n",
        "\n",
        "        # Optional: Box plot (Company Name Length)\n",
        "        st.write(\"Rendering: Box Plot (Company Name Length)\")\n",
        "        df['Company Name Length'] = df['Company'].str.len()\n",
        "        if df['Company Name Length'].isna().all():\n",
        "            st.warning(\"No valid company name lengths for Box Plot. Check 'Company' column.\")\n",
        "        else:\n",
        "            fig7 = px.box(df, y='Company Name Length',\n",
        "                          title=\"Distribution of Company Name Lengths\")\n",
        "            st.plotly_chart(fig7)\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error rendering visualizations: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6Kdxd4qtC5h",
        "outputId": "957afec3-5c3b-43b9-dd31-fdee3bbd08c9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-08 15:42:50.341 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.344 No runtime found, using MemoryCacheStorageManager\n",
            "2025-07-08 15:42:50.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.351 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.352 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.353 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.354 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.355 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.357 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.358 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.359 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.360 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.361 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.362 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.364 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.364 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.366 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.371 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.378 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.379 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.380 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.382 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.383 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.387 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.388 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.389 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.390 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.391 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.392 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.393 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.393 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.394 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.395 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.396 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.396 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.397 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.398 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.399 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.399 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.400 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.400 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.401 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.402 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.403 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.403 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.404 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:42:50.404 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ~/.streamlit/cache"
      ],
      "metadata": {
        "id": "IByBsMKjtMh-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "from pathlib import Path\n",
        "\n",
        "# Set page config\n",
        "st.set_page_config(page_title=\"Customer Manager & Analyzer\", layout=\"wide\")\n",
        "\n",
        "# Load and clean data\n",
        "@st.cache_data\n",
        "def load_and_clean_data(file_path):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        df = df.drop_duplicates()\n",
        "        df = df.dropna(subset=['First Name', 'Email'])\n",
        "        df = df.drop(columns=['Index', 'Subscription Date'], errors='ignore')\n",
        "        st.write(\"Data loaded and cleaned successfully.\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading data: {e}\")\n",
        "        return None\n",
        "\n",
        "# File path\n",
        "file_path = \"customers-100.csv\"\n",
        "df = load_and_clean_data(file_path)\n",
        "if df is None:\n",
        "    st.stop()\n",
        "\n",
        "# Sidebar for navigation\n",
        "st.sidebar.title(\"Navigation\")\n",
        "view = st.sidebar.radio(\"Select View\", [\"Overview\", \"Table\", \"Stats\"])\n",
        "\n",
        "# Clear cache button\n",
        "if st.sidebar.button(\"Clear Cache\"):\n",
        "    st.cache_data.clear()\n",
        "    st.write(\"Cache cleared. Please refresh the page.\")\n",
        "\n",
        "# Overview View\n",
        "if view == \"Overview\":\n",
        "    st.title(\"Customer Data Overview\")\n",
        "    st.write(\"Summary statistics of the cleaned customer dataset.\")\n",
        "    total_customers = len(df)\n",
        "    unique_countries = df['Country'].nunique()\n",
        "    most_common_country = df['Country'].mode()[0]\n",
        "    top_3_cities = df['City'].value_counts().head(3).index.tolist()\n",
        "    top_5_companies = df['Company'].value_counts().head(5).index.tolist()\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        st.metric(\"Total Customers\", total_customers)\n",
        "        st.metric(\"Unique Countries\", unique_countries)\n",
        "    with col2:\n",
        "        st.metric(\"Most Common Country\", most_common_country)\n",
        "        st.write(\"Top 3 Cities:\", \", \".join(top_3_cities))\n",
        "        st.write(\"Top 5 Companies:\", \", \".join(top_5_companies))\n",
        "\n",
        "# Table View\n",
        "elif view == \"Table\":\n",
        "    st.title(\"Editable Customer Table\")\n",
        "    st.write(\"Edit the dataset below and download the updated version.\")\n",
        "    edited_df = st.data_editor(df, num_rows=\"dynamic\")\n",
        "    if st.button(\"Export Edited Data\"):\n",
        "        edited_df.to_csv(\"edited_customers.csv\", index=False)\n",
        "        st.download_button(\n",
        "            label=\"Download Edited CSV\",\n",
        "            data=Path(\"edited_customers.csv\").read_bytes(),\n",
        "            file_name=\"edited_customers.csv\",\n",
        "            mime=\"text/csv\"\n",
        "        )\n",
        "\n",
        "# Stats View\n",
        "elif view == \"Stats\":\n",
        "    st.title(\"Customer Data Visualizations\")\n",
        "    st.write(\"Graphical insights into customer distribution.\")\n",
        "\n",
        "    try:\n",
        "        # Bar chart: Top 5 countries\n",
        "        st.write(\"Rendering: Top 5 Countries Bar Chart\")\n",
        "        top_5_countries = df['Country'].value_counts().head(5)\n",
        "        fig1 = px.bar(x=top_5_countries.index, y=top_5_countries.values,\n",
        "                      labels={'x': 'Country', 'y': 'Customer Count'}, title=\"Top 5 Countries by Customer Count\")\n",
        "        st.plotly_chart(fig1)\n",
        "\n",
        "        # Bar chart: Top 5 cities\n",
        "        st.write(\"Rendering: Top 5 Cities Bar Chart\")\n",
        "        top_5_cities = df['City'].value_counts().head(5)\n",
        "        fig2 = px.bar(x=top_5_cities.index, y=top_5_cities.values,\n",
        "                      labels={'x': 'City', 'y': 'Customer Count'}, title=\"Top 5 Cities by Customer Count\")\n",
        "        st.plotly_chart(fig2)\n",
        "\n",
        "        # Pie chart: Country distribution (Top 5 + Others)\n",
        "        st.write(\"Rendering: Country Distribution Pie Chart\")\n",
        "        country_counts = df['Country'].value_counts()\n",
        "        top_n = 5\n",
        "        top_countries = country_counts.head(top_n)\n",
        "        others_count = country_counts.iloc[top_n:].sum()\n",
        "        pie_data = pd.concat([top_countries, pd.Series([others_count], index=['Others'])])\n",
        "        fig3 = px.pie(names=pie_data.index, values=pie_data.values,\n",
        "                      title=f\"Customer Distribution by Country (Top {top_n} + Others)\")\n",
        "        st.plotly_chart(fig3)\n",
        "\n",
        "        # Pie chart: Email domains\n",
        "        st.write(\"Rendering: Email Domains Pie Chart\")\n",
        "        df['Email Domain'] = df['Email'].apply(lambda x: x.split('@')[1] if pd.notna(x) else 'Unknown')\n",
        "        email_domain_counts = df['Email Domain'].value_counts().head(5)\n",
        "        fig4 = px.pie(names=email_domain_counts.index, values=email_domain_counts.values,\n",
        "                      title=\"Customer Distribution by Email Domain\")\n",
        "        st.plotly_chart(fig4)\n",
        "\n",
        "        # Horizontal bar: Top 10 companies\n",
        "        st.write(\"Rendering: Top 10 Companies Horizontal Bar Chart\")\n",
        "        top_10_companies = df['Company'].value_counts().head(10)\n",
        "        fig5 = px.bar(y=top_10_companies.index, x=top_10_companies.values, orientation='h',\n",
        "                      labels={'x': 'Customer Count', 'y': 'Company'}, title=\"Top 10 Companies by Customer Count\")\n",
        "        st.plotly_chart(fig5)\n",
        "\n",
        "        # Optional: Stacked bar chart (Country + Email Availability)\n",
        "        st.write(\"Rendering: Stacked Bar Chart (Country + Email Availability)\")\n",
        "        email_availability = df.copy()\n",
        "        email_availability['Email Status'] = email_availability['Email'].isna().map({True: 'Missing Email', False: 'Has Email'})\n",
        "        stacked_data = email_availability.groupby(['Country', 'Email Status']).size().unstack(fill_value=0)\n",
        "        if stacked_data.empty:\n",
        "            st.warning(\"No data available for Stacked Bar Chart. Check 'Email' column.\")\n",
        "        else:\n",
        "            fig6 = px.bar(stacked_data, barmode='stack',\n",
        "                          title=\"Customers by Country and Email Availability\",\n",
        "                          labels={'value': 'Customer Count', 'Country': 'Country'})\n",
        "            st.plotly_chart(fig6)\n",
        "\n",
        "        # Optional: Box plot (Company Name Length)\n",
        "        st.write(\"Rendering: Box Plot (Company Name Length)\")\n",
        "        df['Company Name Length'] = df['Company'].str.len()\n",
        "        if df['Company Name Length'].isna().all():\n",
        "            st.warning(\"No valid company name lengths for Box Plot. Check 'Company' column.\")\n",
        "        else:\n",
        "            fig7 = px.box(df, y='Company Name Length',\n",
        "                          title=\"Distribution of Company Name Lengths\")\n",
        "            st.plotly_chart(fig7)\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error rendering visualizations: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QGNU3bvtQnV",
        "outputId": "713fc236-dbb1-4305-d0d5-789fd7175460"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-08 15:43:46.048 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.051 No runtime found, using MemoryCacheStorageManager\n",
            "2025-07-08 15:43:46.055 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.056 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.057 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.058 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.059 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.060 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.061 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.063 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.063 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.064 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.065 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.066 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.067 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.068 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.069 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.070 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.072 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.074 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.075 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.076 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.077 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.077 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.082 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.083 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.084 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.085 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.086 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.087 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.088 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.089 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.089 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.090 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.091 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.091 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.098 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.099 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.099 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.100 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.101 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.105 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.106 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.107 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.107 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.108 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.108 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-07-08 15:43:46.113 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "from pathlib import Path\n",
        "\n",
        "# Set page config\n",
        "st.set_page_config(page_title=\"Customer Manager & Analyzer\", layout=\"wide\")\n",
        "\n",
        "# Load and clean data\n",
        "@st.cache_data\n",
        "def load_and_clean_data(file_path):\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        df = df.drop_duplicates()\n",
        "        df = df.dropna(subset=['First Name', 'Email'])\n",
        "        df = df.drop(columns=['Index', 'Subscription Date'], errors='ignore')\n",
        "        st.write(\"Data loaded and cleaned successfully.\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading data: {e}\")\n",
        "        return None\n",
        "\n",
        "# File path\n",
        "file_path = \"customers-100.csv\"\n",
        "df = load_and_clean_data(file_path)\n",
        "if df is None:\n",
        "    st.stop()\n",
        "\n",
        "# Sidebar for navigation\n",
        "st.sidebar.title(\"Navigation\")\n",
        "view = st.sidebar.radio(\"Select View\", [\"Overview\", \"Table\", \"Stats\"])\n",
        "\n",
        "# Clear cache button\n",
        "if st.sidebar.button(\"Clear Cache\"):\n",
        "    st.cache_data.clear()\n",
        "    st.write(\"Cache cleared. Please refresh the page.\")\n",
        "\n",
        "# Overview View\n",
        "if view == \"Overview\":\n",
        "    st.title(\"Customer Data Overview\")\n",
        "    st.write(\"Summary statistics of the cleaned customer dataset.\")\n",
        "    total_customers = len(df)\n",
        "    unique_countries = df['Country'].nunique()\n",
        "    most_common_country = df['Country'].mode()[0]\n",
        "    top_3_cities = df['City'].value_counts().head(3).index.tolist()\n",
        "    top_5_companies = df['Company'].value_counts().head(5).index.tolist()\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        st.metric(\"Total Customers\", total_customers)\n",
        "        st.metric(\"Unique Countries\", unique_countries)\n",
        "    with col2:\n",
        "        st.metric(\"Most Common Country\", most_common_country)\n",
        "        st.write(\"Top 3 Cities:\", \", \".join(top_3_cities))\n",
        "        st.write(\"Top 5 Companies:\", \", \".join(top_5_companies))\n",
        "\n",
        "# Table View\n",
        "elif view == \"Table\":\n",
        "    st.title(\"Editable Customer Table\")\n",
        "    st.write(\"Edit the dataset below and download the updated version.\")\n",
        "    edited_df = st.data_editor(df, num_rows=\"dynamic\")\n",
        "    if st.button(\"Export Edited Data\"):\n",
        "        edited_df.to_csv(\"edited_customers.csv\", index=False)\n",
        "        st.download_button(\n",
        "            label=\"Download Edited CSV\",\n",
        "            data=Path(\"edited_customers.csv\").read_bytes(),\n",
        "            file_name=\"edited_customers.csv\",\n",
        "            mime=\"text/csv\"\n",
        "        )\n",
        "\n",
        "# Stats View\n",
        "elif view == \"Stats\":\n",
        "    st.title(\"Customer Data Visualizations\")\n",
        "    st.write(\"Graphical insights into customer distribution.\")\n",
        "\n",
        "    try:\n",
        "        # Bar chart: Top 5 countries\n",
        "        st.write(\"Rendering: Top 5 Countries Bar Chart\")\n",
        "        top_5_countries = df['Country'].value_counts().head(5)\n",
        "        fig1 = px.bar(x=top_5_countries.index, y=top_5_countries.values,\n",
        "                      labels={'x': 'Country', 'y': 'Customer Count'}, title=\"Top 5 Countries by Customer Count\")\n",
        "        st.plotly_chart(fig1)\n",
        "\n",
        "        # Bar chart: Top 5 cities\n",
        "        st.write(\"Rendering: Top 5 Cities Bar Chart\")\n",
        "        top_5_cities = df['City'].value_counts().head(5)\n",
        "        fig2 = px.bar(x=top_5_cities.index, y=top_5_cities.values,\n",
        "                      labels={'x': 'City', 'y': 'Customer Count'}, title=\"Top 5 Cities by Customer Count\")\n",
        "        st.plotly_chart(fig2)\n",
        "\n",
        "        # Pie chart: Country distribution (Top 5 + Others)\n",
        "        st.write(\"Rendering: Country Distribution Pie Chart\")\n",
        "        country_counts = df['Country'].value_counts()\n",
        "        top_n = 5\n",
        "        top_countries = country_counts.head(top_n)\n",
        "        others_count = country_counts.iloc[top_n:].sum()\n",
        "        pie_data = pd.concat([top_countries, pd.Series([others_count], index=['Others'])])\n",
        "        fig3 = px.pie(names=pie_data.index, values=pie_data.values,\n",
        "                      title=f\"Customer Distribution by Country (Top {top_n} + Others)\")\n",
        "        st.plotly_chart(fig3)\n",
        "\n",
        "        # Pie chart: Email domains\n",
        "        st.write(\"Rendering: Email Domains Pie Chart\")\n",
        "        df['Email Domain'] = df['Email'].apply(lambda x: x.split('@')[1] if pd.notna(x) else 'Unknown')\n",
        "        email_domain_counts = df['Email Domain'].value_counts().head(5)\n",
        "        fig4 = px.pie(names=email_domain_counts.index, values=email_domain_counts.values,\n",
        "                      title=\"Customer Distribution by Email Domain\")\n",
        "        st.plotly_chart(fig4)\n",
        "\n",
        "        # Horizontal bar: Top 10 companies\n",
        "        st.write(\"Rendering: Top 10 Companies Horizontal Bar Chart\")\n",
        "        top_10_companies = df['Company'].value_counts().head(10)\n",
        "        fig5 = px.bar(y=top_10_companies.index, x=top_10_companies.values, orientation='h',\n",
        "                      labels={'x': 'Customer Count', 'y': 'Company'}, title=\"Top 10 Companies by Customer Count\")\n",
        "        st.plotly_chart(fig5)\n",
        "\n",
        "        # Optional: Stacked bar chart (Country + Email Availability)\n",
        "        st.write(\"Rendering: Stacked Bar Chart (Country + Email Availability)\")\n",
        "        email_availability = df.copy()\n",
        "        email_availability['Email Status'] = email_availability['Email'].isna().map({True: 'Missing Email', False: 'Has Email'})\n",
        "        stacked_data = email_availability.groupby(['Country', 'Email Status']).size().unstack(fill_value=0)\n",
        "        if stacked_data.empty:\n",
        "            st.warning(\"No data available for Stacked Bar Chart. Check 'Email' column.\")\n",
        "        else:\n",
        "            fig6 = px.bar(stacked_data, barmode='stack',\n",
        "                          title=\"Customers by Country and Email Availability\",\n",
        "                          labels={'value': 'Customer Count', 'Country': 'Country'})\n",
        "            st.plotly_chart(fig6)\n",
        "\n",
        "        # Optional: Box plot (Company Name Length)\n",
        "        st.write(\"Rendering: Box Plot (Company Name Length)\")\n",
        "        df['Company Name Length'] = df['Company'].str.len()\n",
        "        if df['Company Name Length'].isna().all():\n",
        "            st.warning(\"No valid company name lengths for Box Plot. Check 'Company' column.\")\n",
        "        else:\n",
        "            fig7 = px.box(df, y='Company Name Length',\n",
        "                          title=\"Distribution of Company Name Lengths\")\n",
        "            st.plotly_chart(fig7)\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error rendering visualizations: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HgzMd57tkr2",
        "outputId": "c8a548d2-6bbf-477f-ee90-85623f2e020e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "\n",
        "# Start Streamlit server\n",
        "process = subprocess.Popen(['streamlit', 'run', 'app.py', '--server.port', '8501'])\n",
        "\n",
        "# Create a public URL with ngrok\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Streamlit app is running at: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "cU76n7kTtpKP",
        "outputId": "60fa3aa1-1ac7-4056-ccf7-7a95906114c8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-07-08T15:45:26+0000 lvl=warn msg=\"failed to start tunnel\" pg=/api/tunnels id=d6490968e970d48c err=\"failed to start tunnel: Your account may not run more than 3 tunnels over a single ngrok agent session.\\nThe tunnels already running on this session are:\\ntn_2zawY0V1CBR4wJnDL6qIL4YdlTS, tn_2zayKgadmizJIhnhxdhA7RBufEC, tn_2zb9BcOkI8JmXdKKOiaoQkXGJti\\n\\r\\n\\r\\nERR_NGROK_324\\r\\n\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PyngrokNgrokHTTPError",
          "evalue": "ngrok client exception, API returned 502: {\"error_code\":103,\"status_code\":502,\"msg\":\"failed to start tunnel\",\"details\":{\"err\":\"failed to start tunnel: Your account may not run more than 3 tunnels over a single ngrok agent session.\\nThe tunnels already running on this session are:\\ntn_2zawY0V1CBR4wJnDL6qIL4YdlTS, tn_2zayKgadmizJIhnhxdhA7RBufEC, tn_2zb9BcOkI8JmXdKKOiaoQkXGJti\\n\\r\\n\\r\\nERR_NGROK_324\\r\\n\"}}\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout, auth)\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m         \u001b[0mresponse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    635\u001b[0m                 'http', request, response, code, msg, hdrs)\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 502: Bad Gateway",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mPyngrokNgrokHTTPError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-30-601603075.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Create a public URL with ngrok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8501\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Streamlit app is running at: {public_url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Creating tunnel with options: {options}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m     tunnel = NgrokTunnel(api_request(f\"{api_url}/api/tunnels\", method=\"POST\", data=options,\n\u001b[0m\u001b[1;32m    390\u001b[0m                                      timeout=pyngrok_config.request_timeout),\n\u001b[1;32m    391\u001b[0m                          pyngrok_config, api_url)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout, auth)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Response {status_code}: {response_data.strip()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         raise PyngrokNgrokHTTPError(f\"ngrok client exception, API returned {status_code}: {response_data}\",\n\u001b[0m\u001b[1;32m    649\u001b[0m                                     \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m                                     status_code, e.reason, e.headers, response_data)\n",
            "\u001b[0;31mPyngrokNgrokHTTPError\u001b[0m: ngrok client exception, API returned 502: {\"error_code\":103,\"status_code\":502,\"msg\":\"failed to start tunnel\",\"details\":{\"err\":\"failed to start tunnel: Your account may not run more than 3 tunnels over a single ngrok agent session.\\nThe tunnels already running on this session are:\\ntn_2zawY0V1CBR4wJnDL6qIL4YdlTS, tn_2zayKgadmizJIhnhxdhA7RBufEC, tn_2zb9BcOkI8JmXdKKOiaoQkXGJti\\n\\r\\n\\r\\nERR_NGROK_324\\r\\n\"}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill ngrok"
      ],
      "metadata": {
        "id": "oOFdX3_xuJ2X"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill streamlit"
      ],
      "metadata": {
        "id": "2l-zvxAOuNJf"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ps aux | grep ngrok\n",
        "!ps aux | grep streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BttLLqJ9uSkS",
        "outputId": "613fa07b-88bd-4901-95af-a9d2a42e1f28"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root       95033  0.0  0.0   7376  3572 ?        S    15:48   0:00 /bin/bash -c ps aux | grep ngrok\n",
            "root       95035  0.0  0.0   6484  2280 ?        S    15:48   0:00 grep ngrok\n",
            "root       37626  0.0  0.0      0     0 ?        Z    13:07   0:00 [streamlit] <defunct>\n",
            "root       94016  0.4  0.0      0     0 ?        Z    15:45   0:00 [streamlit] <defunct>\n",
            "root       95037  0.0  0.0   7376  3444 ?        S    15:48   0:00 /bin/bash -c ps aux | grep streamlit\n",
            "root       95039  0.0  0.0   6484  2300 ?        S    15:48   0:00 grep streamlit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ~/.streamlit/cache"
      ],
      "metadata": {
        "id": "gDkunWJuuZCg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "# Terminate existing ngrok tunnels\n",
        "!pkill ngrok\n",
        "!pkill streamlit\n",
        "\n",
        "# Start Streamlit server\n",
        "process = subprocess.Popen(['streamlit', 'run', 'app.py', '--server.port', '8501'])\n",
        "\n",
        "# Wait briefly to ensure Streamlit starts\n",
        "time.sleep(5)\n",
        "\n",
        "# Create a public URL with ngrok\n",
        "try:\n",
        "    public_url = ngrok.connect(8501)\n",
        "    print(f\"Streamlit app is running at: {public_url}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating ngrok tunnel: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFRewm2XufDO",
        "outputId": "143bb45e-8d5c-4aae-ded2-bf36f58e8072"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app is running at: NgrokTunnel: \"https://b14c715850b3.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}